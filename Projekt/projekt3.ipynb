{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt IAU  \n",
    "## 3. časť - Strojové učenie\n",
    "### Vypracovali: Martin Kukučka, Martin Jankuliak\n",
    "### Číslo datasetu: 80\n",
    "### Podiel práce: 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from numpy.random import seed \n",
    "from numpy.random import randn \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import exp\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from numpy import percentile\n",
    "\n",
    "import scipy as sc\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia, ktorá nahradí chýbajúce hodnoty v stĺpci column modusom (najviac vyskytovaný element). Funkcia využíva SimpleImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(data_frame, column):\n",
    "    data = data_frame[column].values.reshape(-1, 1)\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    data_frame[column] = imp.fit_transform(data)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia, ktorá nahradí chýbajúce hodnoty v stĺpci column mediánom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(data_frame, column):\n",
    "    median = data_frame[column].median()\n",
    "    data_frame[column].fillna(median, inplace = True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia, ktorá nahradí chýbajúce hodnoty v stĺpci column priemerom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(data_frame, column):\n",
    "    mean = data_frame[column].mean()\n",
    "    data_frame[column].fillna(mean, inplace = True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naplnenie chýbajúcich hodnôt v stĺpci / stĺpcoch modusom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fill_mode(data_frame, columns):\n",
    "    for col in columns:\n",
    "        data_frame = get_mode(data_frame, col)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naplnenie chýbajúcich hodnôt v stĺpci / stĺpcoch mediánom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fill_median(data_frame, columns):\n",
    "    for col in columns:\n",
    "        data_frame = get_median(data_frame, col)\n",
    "        \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naplnenie chýbajúcich hodnôt v stĺpci / stĺpcoch priemerom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fill_mean(data_frame, columns):\n",
    "    for col in columns:\n",
    "        data_frame = get_mean(data_frame, col)\n",
    "        \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocou tejto funkcie prevádzame adresu na numerickú hodnotu tak, že z danej adresy zistíme ZIP code / PSČ a uložíme ho do pôvodného záznamu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip(data_frame, column):\n",
    "    for i in range(len(data_frame[column])):\n",
    "        zipcode = str(data_frame[column][i])\n",
    "        data_frame.loc[i, column] = zipcode[len(zipcode) - 5:len(zipcode)]\n",
    "    data_frame[column] = data_frame[column].astype('int')\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia ráta vek respondentov v záznamoch. Našou analýzou sme zistili, že záznamy sú robené v rokoch 2018 a 2019. Z každého záznamu vezmeme atribút age a ak je hodnota tohto atribútu záporná alebo trojciferná (uvažujeme ako outliery), tak pomocou atribútu date-of-birth vypočítame nový vek. Ak nový vek zostane naďalej záporný alebo trojciferný, tak jednoducho tieto záznamy vymažeme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(data_frame, date_of_birth, age):\n",
    "    for i in range(len(data_frame[date_of_birth])):\n",
    "        curr_age = int(data_frame[age][i])\n",
    "        \n",
    "        if curr_age < 0 or curr_age > 99:\n",
    "            year = data_frame[date_of_birth][i]\n",
    "            year = year[:4]            \n",
    "            new_age = 2019 - int(year)\n",
    "            \n",
    "            if new_age < 0 or new_age > 99:\n",
    "                data_frame = data_frame.drop(i)\n",
    "            else:\n",
    "                data_frame.loc[i, age] = str(new_age)\n",
    "                \n",
    "    data_frame = data_frame.reset_index()\n",
    "    data_frame = data_frame.drop('index', 1)        \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia, ktorá zjednotí duplikáty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_rows(data_frame):\n",
    "    aggregation_functions = {}\n",
    "    for col in data_frame.columns:\n",
    "        aggregation_functions[col] = \"first\" \n",
    "\n",
    "    return data_frame.groupby(data_frame['name'], as_index=False).aggregate(aggregation_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocou tejto funkcie sme nahradzovali formáty hodnôt iba jednou hodnotou. Napr. hodnoty v atribúte pregnant (F, FALSE, f) sme nahradili hodnotou f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_some_values(data_frame, column, change_from, change_to):\n",
    "    for i in range(len(change_from)):\n",
    "        data_frame.loc[data_frame[column] == change_from[i], column] = change_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V tejto funkcií sme pre každý atribút, kde sme uznali, že by bolo vhodné, zjednotili dáta. Vyuzili sme pipeline-u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_values(data_frame):\n",
    "    unify_ppl = Pipeline([\n",
    "                    ('1. step',  cleanse_some_values(data_frame, 'pregnant', [\"F\", \"FALSE\"], \"f\")),\n",
    "                    ('2. step', cleanse_some_values(data_frame, 'pregnant', [\"T\", \"TRUE\"], \"t\")),\n",
    "\n",
    "                    ('3. step', cleanse_some_values(data_frame, 'marital-status', [\" Widowed\", \" Never-married\", \" Divorced\"], \"single\")),\n",
    "                    ('4. step',cleanse_some_values(data_frame, 'marital-status', [\" Married-civ-spouse\", \" Separated\", \" Married-AF-spouse\", \" Married-spouse-absent\"], \"married\")),\n",
    "\n",
    "                    ('5. step', cleanse_some_values(data_frame, 'education', [\" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \" 11th\", \" 12th\"], \"Primary school\")),\n",
    "                    ('6. step', cleanse_some_values(data_frame, 'education', [\" Bachelors\", \" Masters\", \" Doctorate\"], \"College\")),\n",
    "                    ('7. step', cleanse_some_values(data_frame, 'education', [\" Assoc-voc\", \" HS-grad\", \" Prof-school\", \" Assoc-acdm\", \" Some-college\"], \"Highschool\")),\n",
    "                    ('8. step', cleanse_some_values(data_frame, 'education', [\" Preschool\"], \"Preschool\")),\n",
    "\n",
    "                    ('9. step', cleanse_some_values(data_frame, 'workclass', [\" Private\"], \"private\")),\n",
    "                    ('10. step', cleanse_some_values(data_frame, 'workclass', [\" Self-emp-not-inc\", \" Self-emp-inc\", \"self-emp-inc\", \"self-emp-not-inc\"], \"self-emp\")),\n",
    "                    ('11. step', cleanse_some_values(data_frame, 'workclass', [\" Never-worked\", \" Without-pay\"], \"not-working\")),\n",
    "                    ('12. step', cleanse_some_values(data_frame, 'workclass', [\" Local-gov\", \"local-gov\", \" State-gov\", \"state-gov\", \" Federal-gov\", \"federal-gov\"], \"government\")),\n",
    "                    ('13. step', cleanse_some_values(data_frame, 'workclass', [\" ?\", \"?\"], np.nan))\n",
    "                    ])\n",
    "    unify_ppl = unify_ppl.fit(data_frame)\n",
    "    data_frame = unify_ppl.transform(data_frame)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia na zjednotenie formátu dátumov vo formáte YEAR-MONTH-DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date_format(data_frame, column):\n",
    "    for i in range(len(data_frame[column])):\n",
    "        date_format = str(data_frame[column][i])\n",
    "        date_format = date_format.replace('/', '-')\n",
    "        if date_format[2] == '-' and len(date_format) < 10:\n",
    "            temp_year = int(date_format[:2])\n",
    "            if(temp_year <= 20):\n",
    "                if(temp_year < 10):\n",
    "                    year = '200'+str(temp_year)\n",
    "                else:\n",
    "                    year = '20'+str(temp_year)\n",
    "            else:\n",
    "                year = '19'+str(temp_year)\n",
    "            data_frame.loc[i, column] = year+date_format[2:10]\n",
    "        elif date_format[2] == '-' and len(date_format) == 10:\n",
    "            day = date_format[:2]\n",
    "            month = date_format[3:5]\n",
    "            year = date_format[6:10]\n",
    "            data_frame.loc[i, column] = year+'-'+month+'-'+day\n",
    "        else:\n",
    "            data_frame.loc[i, column] = date_format[:10]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia zmaže outliery (v našom zadaní sme sa snažili outliery radšej nahrádzať ako mazať, preto nebolo potrebné túto funkciu použiť)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(data_frame, column):\n",
    "#     a = data_frame[column]\n",
    "#     lower = a.quantile(0.25) - 1.5 * stats.iqr(a)\n",
    "#     upper = a.quantile(0.75) + 1.5 * stats.iqr(a)\n",
    "    \n",
    "#     outliers = a[(a > upper) | (a < lower)]\n",
    "#     data_frame = data_frame.drop(outliers.index)\n",
    "    \n",
    "#     data_frame = data_frame.reset_index()\n",
    "#     data_frame = data_frame.drop('index', 1)\n",
    "    \n",
    "#     return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ďalšia funkcia na zmazanie outlierov (Interquartile Range Method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers_iqr(data_frame, column):\n",
    "#     seed(1)\n",
    "#     data = data_frame[column]\n",
    "#     sns.distplot(data)\n",
    "\n",
    "#     # calculate interquartile range\n",
    "#     q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "#     iqr = q75 - q25\n",
    "#     print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr)) \n",
    "\n",
    "#     # calculate the outlier cutoff\n",
    "#     cut_off = iqr * 1.5\n",
    "#     lower, upper = q25 - cut_off, q75 + cut_off\n",
    "#     print('cutoff=', cut_off, 'lower=', lower, 'upper=', upper)\n",
    "\n",
    "#     # identify outliers\n",
    "#     outliers = data[(data > upper) | (data < lower)]\n",
    "#     print('Identified outliers: %d' % len(outliers))\n",
    "\n",
    "#     # remove outliers\n",
    "#     outliers_removed = [x for x in data if x >= lower and x <= upper] \n",
    "#     print('Non-outlier observations: %d' % len(outliers_removed))\n",
    "\n",
    "#     sns.distplot(outliers_removed)\n",
    "    \n",
    "#     data_frame = data_frame.drop(outliers.index)\n",
    "    \n",
    "#     data_frame = data_frame.reset_index()\n",
    "#     data_frame = data_frame.drop('index', 1)\n",
    "\n",
    "#     return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia slúži na zmenu hodnoty \"t\" atribútu pregnant na \"f\" pre mužov (\" Male\" z atribútu sex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def man_not_pregnant(data_frame, sex, pregnant):\n",
    "    for i in range(len(data_frame[sex])):\n",
    "        if(data_frame[sex][i] == \" Male\") and data_frame[pregnant][i] != \"f\":\n",
    "            data_frame.loc[i, pregnant] = \"f\"\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia transformácie numerických dát, aby boli dáta lepšie distribuované. Zvolili sme metódu yeo-johnson, pretože pracuje nielen s pozitívnymi ale aj s negatívnymi hodnotami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data_frame, columns):\n",
    "    for col in columns:\n",
    "        data = data_frame[col].values.reshape(-1, 1)\n",
    "        power = PowerTransformer(method='yeo-johnson', standardize=True) \n",
    "        data_frame[col] = power.fit_transform(data)\n",
    "        \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia mení kategorické dáta na numerické. Typ udáva akou formou prebieha kódovanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(data_frame, column, typ):\n",
    "    data = data_frame[column]\n",
    "\n",
    "    if typ == 0:\n",
    "        ce_ordinal = ce.OneHotEncoder(cols=[column])\n",
    "        data_frame[column] = ce_ordinal.fit_transform(data)\n",
    "        \n",
    "    elif typ == 1:\n",
    "        ce_ordinal = ce.OrdinalEncoder(cols=[column])\n",
    "        data_frame[column] = ce_ordinal.fit_transform(data)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia mení kategorické dáta atribútu pregnant na numerické 0 - not pregnant, 1 - pregnant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pregnant(data_frame):\n",
    "    cleanse_some_values(data_frame, 'pregnant', [\"f\"], 0)\n",
    "    cleanse_some_values(data_frame, 'pregnant', [\"t\"], 1)\n",
    "    data_frame['pregnant'] = data_frame['pregnant'].astype('int')\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zakódovanie atribútov obsahujúcich kategorické hodnoty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_objects(data_frame):\n",
    "    data_frame = encoding(data_frame, 'sex', 0)\n",
    "    data_frame = encoding(data_frame, 'race', 1)\n",
    "    data_frame = encoding(data_frame, 'marital-status', 1)\n",
    "    data_frame = encoding(data_frame, 'occupation', 1)\n",
    "    data_frame = encode_pregnant(data_frame)\n",
    "    data_frame = encoding(data_frame, 'relationship', 1)\n",
    "    data_frame = encoding(data_frame, 'education', 1)\n",
    "    data_frame = encoding(data_frame, 'income', 0)\n",
    "    data_frame = encoding(data_frame, 'native-country', 1)\n",
    "    data_frame = encoding(data_frame, 'workclass', 1)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia na načítanie .csv súborov, ich spojenie podľa atribútov name a address a vyhodenie nepotrebných atribútov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(typ):\n",
    "    if(typ == 0):\n",
    "        df_other = read_csv(\"data/other_train.csv\")\n",
    "        df_personal = read_csv(\"data/personal_train.csv\")\n",
    "    elif(typ == 1):\n",
    "        df_other = read_csv(\"data/other_valid.csv\")\n",
    "        df_personal = read_csv(\"data/personal_valid.csv\")\n",
    "\n",
    "    data_frame1 = pd.merge(df_personal, df_other, on=['name', 'address'])\n",
    "\n",
    "    data_frame = unify_rows(data_frame1)\n",
    "\n",
    "    data_frame = data_frame.drop('Unnamed: 0_x', 1)\n",
    "    data_frame = data_frame.drop('Unnamed: 0_y', 1)\n",
    "\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkia detailnejšie rozďeluje atribút medical-info na ďalšie atribúty (do viacero stĺpcov), ktoré sa potom pretypujú na typ float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_medical_info(data_frame):\n",
    "    medical_line = data_frame[\"medical_info\"].str.replace(':', ',').str.replace(\"'\", '').str.replace(\"{\", '').str.replace(\"}\", '')\n",
    "    medical_elements = medical_line.str.split(\",\", -1, expand = True)\n",
    "\n",
    "    diabetes_dataset = {}\n",
    "\n",
    "    for index in range(0, medical_elements.shape[1]):\n",
    "        i = medical_elements[0][0]\n",
    "        if(index % 2 == 0):\n",
    "            diabetes_dataset[medical_elements[index][0]] = medical_elements[index + 1]\n",
    "\n",
    "    diabetes_dataset = pd.DataFrame(diabetes_dataset)\n",
    "    data_frame = pd.concat([data_frame, diabetes_dataset.reindex(data_frame.index)], axis = 1)\n",
    "    data_frame = data_frame.drop(columns = ['medical_info'])\n",
    "    \n",
    "    data_frame['mean_glucose'] = data_frame['mean_glucose'].astype(float)\n",
    "    data_frame['std_glucose'] = data_frame['std_glucose'].astype(float)\n",
    "    data_frame['kurtosis_glucose'] = data_frame['kurtosis_glucose'].astype(float)\n",
    "    data_frame['skewness_glucose'] = data_frame['skewness_glucose'].astype(float)\n",
    "    data_frame['mean_oxygen'] = data_frame['mean_oxygen'].astype(float)\n",
    "    data_frame['std_oxygen'] = data_frame['std_oxygen'].astype(float)\n",
    "    data_frame['kurtosis_oxygen'] = data_frame['kurtosis_oxygen'].astype(float)\n",
    "    data_frame['skewness_oxygen'] = data_frame['skewness_oxygen'].astype(float)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia nahradzuje outliery hodnotami z 5% alebo 95% kvartilu. Použili sme Interquartile Range Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(data_frame, columns):\n",
    "    \n",
    "    for i in range(len(columns)):\n",
    "#         sns.distplot(data_frame[columns[i]])\n",
    "\n",
    "        # calculate interquartile range\n",
    "        q5, q95 = percentile(data_frame[columns[i]], 5), percentile(data_frame[columns[i]], 95)\n",
    "        iqr = q95 - q5\n",
    "#         print('Percentiles: 5th=%.3f, 95th=%.3f, IQR=%.3f' % (q5, q95, iqr)) \n",
    "\n",
    "        # calculate the outlier cutoff\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q5 - cut_off, q95 + cut_off\n",
    "#         print('cutoff=', cut_off, 'lower=', lower + cut_off, 'upper=', upper - cut_off)\n",
    "\n",
    "        # identify outliers\n",
    "        outliers = data_frame[columns[i]][(data_frame[columns[i]] > upper) | (data_frame[columns[i]] < lower)]\n",
    "#         print('Identified outliers: %d' % len(outliers))\n",
    "\n",
    "        # data without outliers\n",
    "        outliers_removed = data_frame[columns[i]][(data_frame[columns[i]] <= upper) & (data_frame[columns[i]] >= lower)]\n",
    "#         print('Non-outlier observations: %d' % len(outliers_removed))\n",
    "\n",
    "\n",
    "        for j, value in data_frame.iterrows():\n",
    "                    if value[columns[i]] < lower:\n",
    "                        data_frame.loc[j, columns[i]] = lower\n",
    "                    elif value[columns[i]] > upper:\n",
    "                        data_frame.loc[j, columns[i]] = upper\n",
    "\n",
    "#         sns.distplot(data_frame[columns[i]])\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kedže niektoré dáta nemôžu byť záporné (jedná sa o štandardnú odchýlku), tak záporné hodnoty tohto atribútu zmeníme na kladné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_positive(data_frame, col):\n",
    "    for i in range(len(data_frame[col])):\n",
    "        data = data_frame[col][i]\n",
    "        if data < 0:\n",
    "            data_frame.loc[i, col] = abs(data)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Využitie kNN imputácie na doplnenie chýbajúcich hodnôt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data_frame, columns):\n",
    "    # summarize total missing\n",
    "    print(\"Missing: \" + str(data_frame.isnull().sum().sum()))\n",
    "\n",
    "#     temp = [col for col in data_frame.columns if data_frame[col].dtypes != 'O']\n",
    "\n",
    "    temp = columns\n",
    "\n",
    "    # define imputer\n",
    "    imputer = KNNImputer()\n",
    "\n",
    "    # fit on the dataset\n",
    "    imputer.fit(data_frame[temp])\n",
    "\n",
    "    # transform the dataset\n",
    "    data_frame[temp] = imputer.transform(data_frame[temp])\n",
    "    Xtrans = imputer.transform(data_frame[temp])\n",
    "\n",
    "    # summarize total missing\n",
    "    print(\"Missing: \" + str(sum(isnan(Xtrans).flatten())))\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute funkcia je hlavná funkcia, ktorá spúšťa všetky ostatné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute():\n",
    "    for i in range(2):\n",
    "        df_merged = load_data(i)\n",
    "        df_merged = split_medical_info(df_merged)\n",
    "        df_merged = unify_values(df_merged)\n",
    "        df_merged = change_date_format(df_merged,'date_of_birth')\n",
    "        df_merged = change_to_positive(df_merged, 'std_glucose')\n",
    "\n",
    "        df_merged = knn(df_merged, ['mean_glucose', 'std_glucose', 'kurtosis_glucose', 'skewness_glucose', \n",
    "                                'mean_oxygen', 'std_oxygen', 'kurtosis_oxygen', 'skewness_oxygen'])\n",
    "        df_merged = fill_median(df_merged, ['education-num', 'fnlwgt', 'hours-per-week'])\n",
    "        df_merged = fill_mode(df_merged, ['class', 'race', 'marital-status', 'occupation', 'pregnant', 'relationship', \n",
    "                                      'education', 'income', 'native-country', 'workclass'])\n",
    "        df_merged = fill_mean(df_merged, ['capital-gain', 'capital-loss'])\n",
    "        df_merged = man_not_pregnant(df_merged, 'sex', 'pregnant')\n",
    "        df_merged = get_zip(df_merged,'address')\n",
    "        df_merged = df_merged.drop('name', 1)\n",
    "        df_merged = calculate_age(df_merged, 'date_of_birth', 'age')\n",
    "        df_merged = df_merged.drop('date_of_birth', 1)\n",
    "        df_merged = encode_objects(df_merged)\n",
    "        df_merged = replace_outliers(df_merged, ['capital-gain', 'capital-loss', 'skewness_oxygen'])\n",
    "    # # V analýze sme zistili, že v atribúte capital-loss sa všetky outliere nahradili rovnakou hodnotou, preto tento atribút \n",
    "    # # nemá žiadnu výpovednú hodnotu a je vhodné ho zmazať (zakomentovať, ak atribút mazať nechceme).\n",
    "        df_merged = df_merged.drop('capital-loss', 1)\n",
    "        df_merged = transform_data(df_merged, ['mean_glucose', 'std_glucose', 'kurtosis_glucose', 'skewness_glucose', \n",
    "                                'mean_oxygen', 'std_oxygen', 'kurtosis_oxygen', 'skewness_oxygen'])\n",
    "    # # Uloženie upravenej dátovej sady do .csv súboru\n",
    "        if i == 0:\n",
    "            df_merged.to_csv(r'data\\train.csv')\n",
    "        elif i == 1:\n",
    "            df_merged.to_csv(r'data\\valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spustenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 895\n",
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\matto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\matto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\matto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 305\n",
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\matto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\matto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\matto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potrebovali sme upraviť kód tak, aby sme pre trénovací aj validačný dataset vykonali rovnaké operácie. Pôvodná funkcia execute() sa vykonávala iba raz a do jedného .csv súboru sa uložil trénovací aj validačný dataset. Teraz sme túto funkciu upravili spoločne s funkciou load_data(), do ktorej sme pridali parameter, ktorý udáva, o ktorý dataset sa jedná. Funkcia execute sa teraz vykonáva dvakrát. Najprv sa spracuje trénovací dataset, uloží sa a rovnaký proces sa vykoná aj pre validačný dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načítanie predspracovaných dát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_csv(\"data/train.csv\")\n",
    "df_valid = read_csv(\"data/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3931 entries, 0 to 3930\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        3931 non-null   int64  \n",
      " 1   address           3931 non-null   int64  \n",
      " 2   age               3931 non-null   int64  \n",
      " 3   sex               3931 non-null   int64  \n",
      " 4   race              3931 non-null   int64  \n",
      " 5   marital-status    3931 non-null   int64  \n",
      " 6   occupation        3931 non-null   int64  \n",
      " 7   pregnant          3931 non-null   int64  \n",
      " 8   education-num     3931 non-null   float64\n",
      " 9   relationship      3931 non-null   int64  \n",
      " 10  capital-gain      3931 non-null   float64\n",
      " 11  education         3931 non-null   int64  \n",
      " 12  fnlwgt            3931 non-null   float64\n",
      " 13  class             3931 non-null   float64\n",
      " 14  income            3931 non-null   int64  \n",
      " 15  native-country    3931 non-null   int64  \n",
      " 16  hours-per-week    3931 non-null   float64\n",
      " 17  workclass         3931 non-null   int64  \n",
      " 18  mean_glucose      3931 non-null   float64\n",
      " 19  std_glucose       3931 non-null   float64\n",
      " 20  kurtosis_glucose  3931 non-null   float64\n",
      " 21  skewness_glucose  3931 non-null   float64\n",
      " 22  mean_oxygen       3931 non-null   float64\n",
      " 23  std_oxygen        3931 non-null   float64\n",
      " 24  kurtosis_oxygen   3931 non-null   float64\n",
      " 25  skewness_oxygen   3931 non-null   float64\n",
      "dtypes: float64(13), int64(13)\n",
      "memory usage: 798.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        1311 non-null   int64  \n",
      " 1   address           1311 non-null   int64  \n",
      " 2   age               1311 non-null   int64  \n",
      " 3   sex               1311 non-null   int64  \n",
      " 4   race              1311 non-null   int64  \n",
      " 5   marital-status    1311 non-null   int64  \n",
      " 6   occupation        1311 non-null   int64  \n",
      " 7   pregnant          1311 non-null   int64  \n",
      " 8   education-num     1311 non-null   float64\n",
      " 9   relationship      1311 non-null   int64  \n",
      " 10  capital-gain      1311 non-null   float64\n",
      " 11  education         1311 non-null   int64  \n",
      " 12  fnlwgt            1311 non-null   float64\n",
      " 13  class             1311 non-null   float64\n",
      " 14  income            1311 non-null   int64  \n",
      " 15  native-country    1311 non-null   int64  \n",
      " 16  hours-per-week    1311 non-null   float64\n",
      " 17  workclass         1311 non-null   int64  \n",
      " 18  mean_glucose      1311 non-null   float64\n",
      " 19  std_glucose       1311 non-null   float64\n",
      " 20  kurtosis_glucose  1311 non-null   float64\n",
      " 21  skewness_glucose  1311 non-null   float64\n",
      " 22  mean_oxygen       1311 non-null   float64\n",
      " 23  std_oxygen        1311 non-null   float64\n",
      " 24  kurtosis_oxygen   1311 non-null   float64\n",
      " 25  skewness_oxygen   1311 non-null   float64\n",
      "dtypes: float64(13), int64(13)\n",
      "memory usage: 266.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
